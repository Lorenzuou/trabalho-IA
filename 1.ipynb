{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heterogeneous pooling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the data will be stored in this dataframe, with the method name, mean accuracy, standard deviation, lower and upper bound\n",
    "df = pd.DataFrame(columns=['method', 'mean', 'std', 'lower', 'upper'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('X.csv')\n",
    "y = pd.read_csv('y.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1026/920309096.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'method': 'ZR', 'mean': scoresZeroR.mean(), 'std': scoresZeroR.std(), 'lower':inf, 'upper': sup}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Zero Rule Baseline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=36851234)\n",
    "\n",
    "scoresZeroR = cross_val_score(clf, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "inf, sup = stats.norm.interval(0.95, loc=scoresZeroR.mean(), scale=scoresZeroR.std()/np.sqrt(len(scoresZeroR)))\n",
    "\n",
    "\n",
    "df = df.append({'method': 'ZR', 'mean': scoresZeroR.mean(), 'std': scoresZeroR.std(), 'lower':inf, 'upper': sup}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(model,params_grid,name, df): \n",
    "    scalar = StandardScaler()\n",
    "    pipe = Pipeline(steps=[('s',scalar), ('m', model)])\n",
    "\n",
    "    outer = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=36851234)\n",
    "    inner = RepeatedStratifiedKFold(n_splits=4, n_repeats=3, random_state=36851234)\n",
    "\n",
    "    gs = GridSearchCV(pipe, param_grid=params_grid, scoring='accuracy', cv=inner, n_jobs=-1)\n",
    "\n",
    "    scores = cross_val_score(gs, X, y.values.ravel(), scoring='accuracy', cv=outer, n_jobs=-1)\n",
    "    \n",
    "\n",
    "    inf, sup = stats.norm.interval(0.95, loc=scores.mean(), scale=scores.std()/np.sqrt(len(scores)))\n",
    "\n",
    "    df_awnser = pd.concat([df, pd.DataFrame({'method': [name], 'mean': [np.mean(scores)], 'std': inf, 'upper': sup})], ignore_index=True)\n",
    "    \n",
    "    return df_awnser, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "bg = BaggingClassifier(random_state=11)\n",
    "\n",
    "name = 'BA'\n",
    "\n",
    "params_grid = {\n",
    "    'm__n_estimators': [3,9,15,21]\n",
    "    } \n",
    "\n",
    "df, scoresBagging = train_model(bg,params_grid,name,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(random_state=11)\n",
    "\n",
    "name = 'AB'\n",
    "\n",
    "params_grid = {\n",
    "    'm__n_estimators': [3,9,15,21]\n",
    "    }\n",
    "\n",
    "df,scoresAda = train_model(ada,params_grid,name,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(random_state=11)\n",
    "\n",
    "name = 'RF'\n",
    "\n",
    "params_grid = {\n",
    "    'm__n_estimators': [3,9,15,21]\n",
    "} \n",
    "\n",
    "\n",
    "df,scoresRandomForest = train_model(rf,params_grid,name,df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df \n",
    "df.to_csv('df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base estimators\n",
    "from sklearn.base import BaseEstimator\n",
    "# import classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "class HeterogeneousEnsemble(BaseEstimator):\n",
    "    # define o construtor para o classificador\n",
    "    def __init__(self,n_samples=3):\n",
    "        \n",
    "        self.classifiers  =  [DecisionTreeClassifier(random_state=11), KNeighborsClassifier(), GaussianNB()]\n",
    "        self.n_samples = n_samples\n",
    "        self.trained_classifiers = []\n",
    "\n",
    "\n",
    "    def train_classifiers(self, X, y):\n",
    "\n",
    "        # converter para numpy array\n",
    "        X = X.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "\n",
    "        # faz o loop sobre os classificadores individuais\n",
    "        for clf in self.classifiers:\n",
    "            # treina o classificador no conjunto de treinamento atual\n",
    "            clf.fit(X, y.ravel())\n",
    "            # adiciona o classificador treinado à lista\n",
    "            self.trained_classifiers.append(clf)\n",
    "        # retorna a lista de classificadores treinados\n",
    "        return self.trained_classifiers\n",
    "\n",
    "    def sample_data(self,X, y, random_state):\n",
    "        # amostra as características com reposição e obtém os rótulos correspondentes\n",
    "        X_sampled = X.sample(frac=1, replace=True, random_state=random_state)\n",
    "        y_sampled = y.loc[X_sampled.index]\n",
    "        # retorna o conjunto de dados amostrado\n",
    "        return X_sampled, y_sampled\n",
    "\n",
    "\n",
    "    def predict_hp(self, X_test, class_order):\n",
    "        # cria um dicionário para armazenar as predições de cada classificador\n",
    "        votes = {}\n",
    "        X_test = X_test.to_numpy().reshape(1, -1)\n",
    "        # faz o loop sobre os classificadores individuais\n",
    "        for clf in self.trained_classifiers:\n",
    "            # prediz a classe do exemplo de teste usando o classificador atual\n",
    "            pred = clf.predict(X_test)\n",
    "            # armazena a predição no dicionário\n",
    "            if pred[0] in votes:\n",
    "                votes[pred[0]] += 1\n",
    "            else:\n",
    "                votes[pred[0]] = 1\n",
    "                \n",
    "\n",
    "        # obtém a(s) classe(s) mais votada(s) e as armazena em uma lista\n",
    "        max_votes = max(votes.values())\n",
    "        most_voted_classes = [k for k,v in votes.items() if v == max_votes]\n",
    "        \n",
    "        hp_pred = None\n",
    "\n",
    "        # se houver mais de uma classe mais votada, quebra o empate usando a ordem das classes do conjunto de treinamento\n",
    "        if len(most_voted_classes) > 1:\n",
    "            for c in class_order:\n",
    "                if c in most_voted_classes:\n",
    "                    hp_pred = c\n",
    "                    break\n",
    "            if hp_pred is None:\n",
    "                hp_pred = most_voted_classes[0]\n",
    "        # caso contrário, retorna a classe mais votada como a predição do conjunto HP\n",
    "        else:\n",
    "            hp_pred = most_voted_classes[0]\n",
    "\n",
    "        # retorna a predição\n",
    "        return hp_pred\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self,X,y): \n",
    "\n",
    "        # # if data is numpy array, convert to pandas dataframe\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = pd.DataFrame(X)\n",
    "        if isinstance(y, np.ndarray):\n",
    "            y = pd.Series(y)\n",
    "\n",
    "        # reset index\n",
    "        X.reset_index(drop=True, inplace=True)\n",
    "        y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        classifiers = [] # ciclo para treinar os classificadores individuais\n",
    "        for i in range(self.n_samples):\n",
    "            # se for a primeira iteração, use os dados de treinamento originais\n",
    "            if i == 0:\n",
    "                X_current = X.copy()\n",
    "                y_current = y.copy()\n",
    "            # caso contrário, crie um novo conjunto de treinamento amostrando com reposição os dados originais usando a função sample_data\n",
    "            else:\n",
    "                X_current, y_current = self.sample_data(X, y, i)\n",
    "            \n",
    "            # treina os classificadores individuais nos dados de treinamento atuais usando a função train_classifiers e os estende à lista\n",
    "            classifiers.extend(self.train_classifiers(X_current, y_current))\n",
    "\n",
    "    def predict(self,X_test): \n",
    "        if(isinstance(X_test, np.ndarray)):\n",
    "            X_test = pd.DataFrame(X_test)\n",
    "        \n",
    "        class_order = y.value_counts().index.tolist()\n",
    "        # cria uma lista vazia para armazenar as predições do conjunto HP\n",
    "        hp_predictions = []\n",
    "        # faz o loop sobre os exemplos de teste\n",
    "        for index, row in X_test.iterrows():\n",
    "            # predict the class of the test example using the predict_hp function and append it to the list # prediz a classe do exemplo de teste usando a função predict_hp e a adiciona à lista\n",
    "            hp_pred = self.predict_hp(row, class_order)\n",
    "            hp_predictions.append(hp_pred)\n",
    "        return hp_predictions\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8166666666666667\n"
     ]
    }
   ],
   "source": [
    "hp2 = HeterogeneousEnsemble(n_samples=3)\n",
    "\n",
    "hp2.fit(X,y)\n",
    "\n",
    "y_pred = hp2.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZR</td>\n",
       "      <td>0.165057</td>\n",
       "      <td>0.010883</td>\n",
       "      <td>0.161163</td>\n",
       "      <td>0.168952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BA</td>\n",
       "      <td>0.511073</td>\n",
       "      <td>0.472997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.549148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB</td>\n",
       "      <td>0.271648</td>\n",
       "      <td>0.259689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.283606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.515517</td>\n",
       "      <td>0.482760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.548274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  method      mean       std     lower     upper\n",
       "0     ZR  0.165057  0.010883  0.161163  0.168952\n",
       "1     BA  0.511073  0.472997       NaN  0.549148\n",
       "2     AB  0.271648  0.259689       NaN  0.283606\n",
       "3     RF  0.515517  0.482760       NaN  0.548274"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hp_Test = HeterogeneousEnsemble(n_samples=9)\n",
    "\n",
    "hp_Test.fit(X,y)\n",
    "\n",
    "\n",
    "hp_predictions = hp_Test.predict(X_test)\n",
    "\n",
    "# avalia a acurácia do conjunto HP no conjunto de teste\n",
    "hp_accuracy = accuracy_score(y_test, hp_predictions)\n",
    "print(f'The accuracy of HP ensemble is {hp_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42352490421455946\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_model(model,params_grid,name, df): \n",
    "    scalar = StandardScaler()\n",
    "    pipe = Pipeline(steps=[('s',scalar), ('m', model)])\n",
    "\n",
    "    outer = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=36851234)\n",
    "    inner = RepeatedStratifiedKFold(n_splits=4, n_repeats=3, random_state=36851234)\n",
    "\n",
    "    gs = GridSearchCV(pipe, param_grid=params_grid, scoring='accuracy', cv=inner, n_jobs=-1)\n",
    "\n",
    "    scores = cross_val_score(gs, X, y.values.ravel(), scoring='accuracy', cv=outer, n_jobs=-1)\n",
    "\n",
    "\n",
    "    print(np.mean(scores))\n",
    "\n",
    "    inf, sup = stats.norm.interval(0.95, loc=scores.mean(), scale=scores.std()/np.sqrt(len(scores)))\n",
    "\n",
    "    df_awnser = pd.concat([df, pd.DataFrame({'method': [name], 'mean': [np.mean(scores)], 'std': [inf], 'upper': [sup]})], ignore_index=True)\n",
    "    # df_awnser = []\n",
    "    return df_awnser, scores\n",
    "\n",
    "# KNN gera um warning em relacao ao parametro keepdims, nao consigo dar surpress nele\n",
    "hp = HeterogeneousEnsemble()\n",
    "\n",
    "name = 'HP'\n",
    "\n",
    "params_grid = {\n",
    "    'm__n_samples': [1,3,5,7]\n",
    "    }\n",
    "\n",
    "df_2, scoresHeteros = train_model(hp,params_grid,name,df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/loren/Desktop/trabalho-IA/1.ipynb Cell 16\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/loren/Desktop/trabalho-IA/1.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39mmean(scores)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scores' is not defined"
     ]
    }
   ],
   "source": [
    "    np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/loren/Desktop/trabalho-IA/1.ipynb Cell 16\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/loren/Desktop/trabalho-IA/1.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39m\u001b[39mdf.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "df.to_csv('df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
